\chapter{Discussion}
\label{chap:results}

After strictly presenting results in the last chapter, this one will discuss the results, morespecific its implications and possible reasons. 
The sequence of results to be discussed remains the same as before.


\section{MVTecAD LOCO Experiments}
\label{sec:locoresultssota}

When comparing the detection and localization results of the approaches analysed last chapter, there is a significant drop in qualtity. 
Although the average in most cases is out of context still an acceptable result, it poses a poor performance compared with prior 
IAD standards. Where on the MVTecAD \cite{MVTEC_Bergmann_2021} most approaches were strictly in a high performance interval above 98 percent 
instance classification and above 97 percent for anomaly localization, a drop of from 10 up to 30 percent in some cases is drastic and significant. 
This information in combination with inferences from figure xyz(figure mit structural vs logical) strongly suggests the latest state of 
the art anomaly detection approaches not being inherently useful when detecting logical anomalies. This is also supported by the 
poor sPRO results. GCAD \cite{LOCODentsAndScratchesBergmann2022}, the approach uniting global and local representations introduced in its 
paper, demonstrates an average sPRO of $0.701$ over all classes which is significantly above the approaches analysed here. As this metric 
is an effective way to observe segmentation capabilities, this last argument is most important. \newline
Another aspect to consider is the nature of both datasets. The MVTecAD \cite{MVTEC_Bergmann_2021} generally uses smaller images than the 
logical dataset, and simpler motives. As the IAD approaches generally shrink input images through resizing for efficiency reasons, 
this means potentially useful information, as well as necessary one when dealing with small anomalies, may be lost. 
Moreover, as visible in figures \ref{fig:mvtecexampleimages} and \ref{fig:pushpinviz}, the MVTecAD LOCO dataset 
has much more objects and motives in one image than merely a simple texture or tile. This makes for much more complex images and anomalous objects 
to detect and thus represents an increased level of complexity over the other dataset. In another way this may emphasize the performance 
difference between analyzed approaches and methods reviewed in \cite{LOCODentsAndScratchesBergmann2022}. \newline

- discuss differences in performance among IAD approaches\newline
-> also if some classifiers were better/had more weaknesses in specific regions that others\newline
-> warten auf DRAEM results dafür, der rest kann zusammengefasst werden


\section{Flat Connector}
\label{sec:flatconnectordiscussion}

- BILDER für logical anomalies!!!

Experiments on the flat connector class produced very high scores. The metrics were not as nrear-perfect as other results on the standard 
MVTecAD \cite{MVTEC_Bergmann_2021} dataset, yet often times significantly higher than the performance on the MVTecAD LOCO \cite{LOCODentsAndScratchesBergmann2022} 
dataset. Picking up on named difficulty discrepancies from last section, the results combined with the nature of the flat connector images 
are consistent with other results. The object in this class possesses a smooth surface, sharp edges and no accessories. With these 
characteristics it is different from classes like the breakfast box or screw bag, who posess either random textures or special properties 
like the semitransparency of the plastic bag. On the other hand the class also consists of logical anomalies that necessarily looked 
like structural ones. An example of this would be the extra hole, which has the same structral properties of other small holes and is 
just misplaced. The flat connector class is thus technically a complementary class of the logical dataset, but definitely comprises 
one of the more easier classes in that set. \newline
As to be expected the segmentations for structural anomalies were overall much more precise than for logical ones. Among logical anomalies 
missing holes were localized most precise. This lets one conclude, that the methodics to fake such an anomaly were not applied perfectly. 
Visual artifacts that are visible after such preprocessing of the class objects were unavoidable with the existing resources and apparently 
helped to detect the according anomalies. The logical anomalies that posed the hardest challenge for most classifiers in terms of localization 
were the extra hole and the differntly sized one. (hier hinschreiben welche classifier mehr und weniger probleme hatten mit den löchern hatten)
Structural anomalies yielded a generally good segmentation if the classifier displayed overall sufficient performance. Very easy to localize 
were cut off edges(bild), which also is to be expected since it very noticeably breaks the contour of the object. Broken edges made for 
varying performance depending on the classifier. SimpleNet often produced very clean segmentations of broken spots(beispiel bild?) and 
(sagen welcher classifier scheiße bei edges war). Scratches were mostly detected correctly, although the segmentations were often 
way thicker that the anomalous region(bild).



\section{Ensemble Performance}
\label{sec:ensemblediscussion}

Here results of all ensemble experiments are discussed in more depth. 

\subsection{Independent Transformation Block}
\label{subsec:ITBfaildiscussion}

- give possible reasons for failure of this methods\newline
-> explain that applying pca to non ensemble features also resulted in this noise, therefore fault must lie with pca\newline
-> give reasons why pca can fail(non linear dependency, ...)\newline


\subsection{Stacking Ensemble}
\label{subsec:stackingdiscussion}


- bei hierarchy ensemble aufgreifen dass training unstabil ist mit 70 auroc weil großteil ja eh anomalous images sind, bzw peaks halt sind wenn das modell viel als anomalous bestimmt.
-> sagen dass bei zu hohen features layers die spezifizität bzw komplexität zu hoch ist und es deswegen suckt

- interpret similar to loco survey section\newline
- also look at how the two experiments performed(hierarchy vs variety)\newline


- sagen bei normalem ensemble dass es an der art und weise der feature concatenation liegen muss, da die einzelnen ensemble members besser sind
-> bild beweis

- fals duo ensemble besser ist als triple sagen dass es zu viele channels sind mit 4608. -> ggf rückshlüsse dass auch 3076 zu viel sein könnten

