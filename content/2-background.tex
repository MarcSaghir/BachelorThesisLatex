\chapter{Background}
\label{chap:background}
This is an algorithm 





\section{Classes of Anomaly detection}
When trying to understand the choices of IAD approaches for the pipeline and ensemble, one first has to learn about a few important distinctions of models on this topic.
The deep learning approaches that have established themselves as state of the art in image anomaly detection are almost exclusively unsupervised approaches. This partiall stems from the fact 
that naturally anomalous images occurr far less than normal images, hence the word "normal". This is especially true in industrial settings, due to the high performance of production factories 
nowadays. Therefore if one were to consider using a supervised learning approach to detect anomalies, either a strong class imbalance or an unrepresentative class distribution would occur.
While there are some solutions for this, they often are either not goo enough for imbalances this high(synonym klÃ¤nge cool) or far to extensive. Some papers like (supervised papers zitieren)
utilize supervised approaches with some success, but still yield a worse performance than the popular unsupervised approaches generally used. Consequently the biggest model distinction is 
between unsupervised and supervised ones. Here it has to be said that there are technically also other settings of IAD one could talk about at this level of observation, but since we are also 
directing our focus to to RGB images, they will not be talked about. Moreover one has to make some simplifications to allow such sharp categorizations of partially interwoven approaches.

The supervised learning category could also further be split up into sub-categories at a lower level. But seeing as the performances of unsupervised approaches dominantely outweigh the 
performance and cost of the former, this work will solely focus on the latter kind of approaches. In the unsupervised IAD setting we then normally distinguish between reconstruction and 
representation based models. One of the key differences between those two is(hier dringend auch paper zitieren die das untersuchen), 


... 


If we now consider the classification of algorithms above, aswell as figure x, we can see that there are quite a lot of unique models and approaches to the same end. To ensure that the built 
pipeline is able to help experiment on images from different points of view, so to say, aswell as ensure that our ensemble approaches cover as various different aspects as possible, it is 
crucial to select approaches from majorly different branches. Here it may be noted that the performance of the single models is not completely disregarded, as those models may prove themselves 
not very useful in the ensemble setting or even as a point of view for experimentation. Therefore certain approaches from the survey papers ...., which yielded performances that were not 
remotely comparable with the highest performing models, were not considered, even if they might cover a previously unrepresented class of IAD setting. 
The main choices were:
- patchcore + paper
- DRAEM + paper
- CSFlow + paper

With this choice we still represent reconstruction and representation based settings somewhat comparably, aswell as providing different examples for a variety of subclasses, namely
distribution maps, autoencoder, memory banks, ....



- there are different kinds of approaches to IAD
- look at tree picture
 
- First important distinction is between supervised and unsupervised
-> we focus on unsupervised
-> list problems with supervised approaches and thus advantages of unsupervised ones

- briefly touch on other IAD settings like few shot, along with references

- among unsupervised approaches, there are two more fundamental distinctions
-> reconstruction based vs representation/feature embedding based
-> explain difference with lots of references

- for reconstruction based touch on 2-3 base categories like GANs etc and link fundamental papers for GANs etc
- for representation based important to explain memory bank, teacher student, and distribution map
- explain normalizing flow somehow somewhere in there

- maybe say which algos we chose and what we covered with that



\section{The Datasets}

-- mvtec2d Dataset:
- cite bergmann papers
- very little Datasets
- hosrt description of mvtec dataset 
-> 15 Classes
-> grayscale masks
-> explain folder structure(maybe with image)
-> example images

-- mvtec LOCO Dataset
- introduced in beyond dents and scratches
- before there were only structural anomalous Datasets
- but to compare the ability of IAD methods for logical constraints, there needs to be another dataset -> neu formulieren damit es nicht nach copypasta aussieht

- short description of LOCO dataset



\section{metrics}

- show metrics from survey papers
- explain which metrics we used and where the other ones are used
- explain also why we used the ones we used, and what disadvantages of other ones where

- touch on paul bergmann paper for sPRO score, say how it is better than pixel auroc and normal pro score, also explain saturation thresholds

- some math formula for calculating the important metrics





\section{description of patchcore algo}


\section{description of simplenet}

\section{description of AST}

\section{description of DRAEM}

\section{description of another reconstruction based algo}
















\input{algotable/sac}