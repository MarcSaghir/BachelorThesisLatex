\chapter{Background}
\label{chap:background}
This is an algorithm 





\section{Classes of Anomaly detection}
When trying to understand the choices of IAD approaches for the pipeline and ensemble, one first has to learn about a few important distinctions of models on this topic.
The deep learning approaches that have established themselves as state of the art in image anomaly detection are almost exclusively unsupervised approaches. This partiall stems from the fact 
that naturally anomalous images occurr far less than normal images, hence the word "normal". This is especially true in industrial settings, due to the high performance of production factories 
nowadays. Therefore if one were to consider using a supervised learning approach to detect anomalies, either a strong class imbalance or an unrepresentative class distribution would occur.
While there are some solutions for this, they often are either not goo enough for imbalances this high(synonym klänge cool) or far to extensive. Some papers like (supervised papers zitieren)
utilize supervised approaches with some success, but still yield a worse performance than the popular unsupervised approaches generally used. Consequently the biggest model distinction is 
between unsupervised and supervised ones. Here it has to be said that there are technically also other settings of IAD one could talk about at this level of observation, but since we are also 
directing our focus to to RGB images, they will not be talked about. Moreover one has to make some simplifications to allow such sharp categorizations of partially interwoven approaches.

The supervised learning category could also further be split up into sub-categories at a lower level. But seeing as the performances of unsupervised approaches dominantely outweigh the 
performance and cost of the former, this work will solely focus on the latter kind of approaches. In the unsupervised IAD setting we then normally distinguish between reconstruction and 
representation based models. One of the key differences between those two is(hier dringend auch paper zitieren die das untersuchen), 


... 


If we now consider the classification of algorithms above, aswell as figure x, we can see that there are quite a lot of unique models and approaches to the same end. To ensure that the built 
pipeline is able to help experiment on images from different points of view, so to say, aswell as ensure that our ensemble approaches cover as various different aspects as possible, it is 
crucial to select approaches from majorly different branches. Here it may be noted that the performance of the single models is not completely disregarded, as those models may prove themselves 
not very useful in the ensemble setting or even as a point of view for experimentation. Therefore certain approaches from the survey papers ...., which yielded performances that were not 
remotely comparable with the highest performing models, were not considered, even if they might cover a previously unrepresented class of IAD setting. 
The main choices were:
- patchcore + paper
- DRAEM + paper
- CSFlow + paper

With this choice we still represent reconstruction and representation based settings somewhat comparably, aswell as providing different examples for a variety of subclasses, namely
distribution maps, autoencoder, memory banks, teacher-student models, diffusion models and ...



- there are different kinds of approaches to IAD
- look at tree picture
 
- First important distinction is between supervised and unsupervised
-> we focus on unsupervised
-> list problems with supervised approaches and thus advantages of unsupervised ones

- briefly touch on other IAD settings like few shot, along with references

- among unsupervised approaches, there are two more fundamental distinctions
-> reconstruction based vs representation/feature embedding based
-> explain difference with lots of references

- for reconstruction based touch on 2-3 base categories like GANs etc and link fundamental papers for GANs etc
- for representation based important to explain memory bank, teacher student, and distribution map
- explain normalizing flow somehow somewhere in there

- maybe say which algos we chose and what we covered with that



\section{The Datasets}
The datasets used in image anomaly detection are scarce, especially when it comes to anomaly detection in a manufacturing setting. There are a few that specialize on certain textures(references) 
and some that can be used for wide ranging categories. What currently stands out as a gold standard among IAD datasets is the MVTecAD(referenz) dataset. It was designed by Bergman et al.(referenz) 
as a highly representative and standardized set of anomalous images along with training images. It has 15 classes from (some examples) to (...). It provides image labels aswell as segmentation 
ground truths, making it versatile and applicable for multiple algorithms. The masks come as black and white grayscale images, while the iamge labels are given through its folder structure. 
Its paradigmatic structure tree can be seen in figure xy.(hier ein satz der die ordner struktur beschreibt) Example images of the dataset are to be seen in figure z. They typically are of a rectangular shape and their resolutions range from 
blabla to blabla. More specifications can be found in (mvtec reference) and the whole dataset is publicly available at (dataset link).\newline
The MVTecAD(referenz) dataset is regarded as the go to dataset(wissenschaftlich formulieren) among IAD papers, and has since its introduction been used in nearly every paper as a dataaset 
to benchmark ones approaches on. This is also likely to remain the trend, since many important algorithms in the recent years have primarily been benmarked on it, forcing new approaches 
to also be benchmarked on this dataset to be comparable to the current SOTA approaches. Due to its importance MVTecAD is one of only two datasets relevant to this work, and serves as a 
comparison to investigate SOTA algoithm performances of the second dataset, which will be our main focus.
\newline
Later in (loco year) Bergman et al(referenz) has introduced another IAD dataset that is loosely related to their original MVTecAD dataset, namely the MVTecAD LOCO dataset(reference). 
This dataset works with the same ground ideas as their original MVTecAD set, but extends the conceptual contents of the dataset by logical anomalies(neu formulieren das klingt scheiße). 
It consists of five class:(class names). The difference to the other dataset is that the anomalous categories for each class are only seperated into good images, images with structural anomalies 
and images with logical anomalies. Structural anomalies being visible damages to the objects, similar to the MVTecAD dataset. Logical anomalies denote violations against arbitrary restrictions 
imposed by Bergmann et al.(referenz). To illustrate this by an example: The class of pushpins represents a birds view of a compartmentised box of pushpins(see figure a). A rule added was, 
that each compartment is only to contain one pushpin. This means that if one region were to miss their contents, or contain two pushpins, it would constitute a logical anomaly. If on the 
other hand a pushpin would have a crooked or broken tip, it would be a structural anomaly. The addition of logical constraints opened an interesting area of research, since the high performance 
of current SOTA algorithms were only measured on structural anomalies so far. Yet it would be insightful to see if those models could also detect logical anomalies, since those also ocurr 
in real life settings, such as manufacturing settings. (Noch ansprechen dass LOCO eine neue metric -> sPRO ermöglicht und die saturation configs ansprechen)
Bergmann et al.(referenz) also released a new IAD model together with the new dataset. The model uses autoencoders(bissi besser beschreiben hier). Unfortunately the code has not been made public. 
Aside from approaches tailored specifically towards the detection of logical anomalies, it would be interesting to see how SOTA methods of structural anomaly detection perform on the LOCO dataset. 
The performance of previous methods on the LOCO dataset is already partially evaluated in some papers like(referenzen von benchmark papers), but will comprehensively be investigated later in this work.
Moreover the novel dataset categories introduced later are composed of structural aswell as logical anomalies and formatted in the MVTecAD LOCO dataset style.
Aside from the conceptual differences in the two datasets, there are slight changes to the structure tree aswell. The anomaly classes are only changed by name, since it is irrellevant for 
the models whether the anomaly name is ""




anmerkungen für text oben:
- beschreiben was mvtec neu bringt: zb dass es näher an real world ist
- saturation thesholds ansprechen



\section{metrics}

- show metrics from survey papers
- explain which metrics we used and where the other ones are used
- explain also why we used the ones we used, and what disadvantages of other ones where

- touch on paul bergmann paper for sPRO score, say how it is better than pixel auroc and normal pro score, also explain saturation thresholds

- some math formula for calculating the important metrics





\section{description of patchcore algo}


\section{description of simplenet}

\section{description of AST}

\section{description of DRAEM}

\section{description of another reconstruction based algo}
















\input{algotable/sac}