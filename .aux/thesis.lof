\babel@toc {english}{}\relax 
\babel@toc {ngerman}{}\relax 
\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Instance images of a screw from \cite {MVTEC_Bergmann_2021} to showcase anomalous objects in manufacturing settings. The images include a regular screw, a screw with a chipped head and a screw with a bent tip.}}{2}{figure.caption.7}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Overview of IAD methods in a global context. The categorization primarily focuses on unsupervised approaches.}}{5}{figure.caption.8}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Visualizations for the general process of representation (left) and reconstruction (right) based IAD methods.}}{6}{figure.caption.9}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Abstract visualization of the functionality of the memory bank concept \cite {liu2024deep}}}{7}{figure.caption.10}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Abstract visualization of the functionality of the teacher-student concept \cite {liu2024deep}}}{8}{figure.caption.11}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Abstract visualization of the functionality of the distribution map concept \cite {liu2024deep}}}{8}{figure.caption.12}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Abstract visualization of the functionality of the one-class classification concept \cite {liu2024deep}}}{9}{figure.caption.13}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Abstract visualization of the functionality of the autoencoder concept \cite {liu2024deep}}}{9}{figure.caption.14}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Structure of PatchCore architecture for training and testing \cite {patchCore2022}.}}{11}{figure.caption.15}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Structure from SimpleNet architecture \cite {liu2023simplenet}.}}{12}{figure.caption.16}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Visualization of reverse distillation approaches \cite {Deng_2022basicrevdist} and \cite {revdist2023}. a) shows the foundational concept of the bottleneck module used for reverse distillation approaches. b) shows the structural architecture of the approach used in this context.}}{13}{figure.caption.17}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Visualization of DRAEM architecture for testing. \cite {Zavrtanik_2021DRAEM}.}}{14}{figure.caption.18}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Example of difference between sPRO and regular PRO through saturation. It shows that for a larger anomalous region that has no required position for the anomalous object to be placed, the sPRO already reaches maximum performance when a sufficiently large region is segmented. Meanwhile, the conventional PRO metric is strictly rising by the ratio of the segmented region to the larger one \cite {LOCODentsAndScratchesBergmann2022}.}}{17}{figure.caption.22}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Examplary image showcasing from the MVTecAD Dataset \cite {MVTEC_Bergmann_2021}. The images are labelled with their corresponding class names.}}{18}{figure.caption.23}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces Logical anomalous image of the pushpin class from the MVTecAD LOCO \cite {LOCODentsAndScratchesBergmann2022} dataset. It contains two pushpin in a single department which violates the ruleset of the class.}}{18}{figure.caption.24}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces Visualizations of the proposed transformation blocks in \cite {EnsembleHeller2023}. The images show the global transformation block in comparison to the independent transformation block \cite {EnsembleHeller2023}}}{21}{figure.caption.25}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Example images of anomalous samples from the novel flat connector class. The according class names are written below the subfigures.}}{24}{figure.caption.26}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Manually taken images from the setup used to record the flat connector class. The images depict a wide shot of the robot mount used, a closer image with a flat connector on the table and a close-up of the process.}}{25}{figure.caption.27}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Visualization of the ensemble pipeline. Multiple pairs of feature extractors (backbones) and feature adapters comprise the new backbones of the ensemble. They are merged using any ensembling methods discussed below and then projected by a global feature adapter. Similar to SimpleNet \cite {liu2023simplenet}, the features are then used to generate fake, noisy features and all maps are used as input to train the discriminator.}}{28}{figure.caption.28}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Illustration of feature representations at different hierarchies. It is visible that lower level features represent more simple structures like edges, whereas higher level features represent complex objects and dependencies. Images taken from \cite {openaifeaturerepres}.}}{29}{figure.caption.29}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces The normed anomaly scores for the MVTecAD \cite {MVTEC_Bergmann_2021} class broken bottle. b) is applied platt scaling calibration. The x-axis represents the anomaly score value for each entry, and the y-axis the confidence for the curve. Here, confidence is defined as the confidence that the sample is anomalous}}{31}{figure.caption.30}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Effects of changing parameters k and t and exemplary calibration for the MVTecAD \cite {MVTEC_Bergmann_2021} class broken bottle}}{31}{figure.caption.31}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Exemplary pixel AUROC comparison of PatchCore \cite {patchCore2022} between structural and logical anomalies. For each evaluation class all normal class images are taken into calculation, resulting into deviating AUROCS from the original reported ones.}}{34}{figure.caption.35}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Representative segmentation results from all classifiers on the breakfast box class of the MVTecAD LOCO \cite {LOCODentsAndScratchesBergmann2022} dataset.}}{35}{figure.caption.36}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Comparison of classifier results on the same image.}}{36}{figure.caption.37}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Example segmentations of DRAEM \cite {Zavrtanik_2021DRAEM}, showcasing its precise segmentation and weakness in localizing missing objects.}}{36}{figure.caption.38}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Exemplary segmentations of representation-based classifiers that showcase less precise segmentaions than reconstruction-based approaches like DRAEM \cite {Zavrtanik_2021DRAEM}.}}{37}{figure.caption.39}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Localization results of all IAd approaches on the novel flat connector class. One instance image for logial and structural anomalies each per approach.}}{38}{figure.caption.41}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces Results of using the Independent Transformation Block \cite {EnsembleHeller2023} for the ensemble process for the flat connector class. These results are also produced when just applying PCA to a single ensemble member and training with it.}}{39}{figure.caption.42}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces Resulting segmentations of ensemble network training when utilizing layer 4.}}{40}{figure.caption.45}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces Training metrics and loss of ensemble network training, utilizing layer 4.}}{40}{figure.caption.46}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces Representative segmentation results from our stacking ensemble with multiple Wideresnet50 backbones at the various hierarchy level. The predictions are done on the novel flat connector class.}}{41}{figure.caption.47}%
\contentsline {figure}{\numberline {5.11}{\ignorespaces Loss of ensemble network using the three standard backbones next to loss of the same network with increased meta epochs and increased discriminator epochs. Not significant difference in loss can be seen after training to new convergence.}}{41}{figure.caption.48}%
\contentsline {figure}{\numberline {5.12}{\ignorespaces Representative segmentation results from our stacking ensemble with different residual network backbones at the same hierarchy level. The predictions are done on the novel flat connector class.}}{42}{figure.caption.49}%
\contentsline {figure}{\numberline {5.13}{\ignorespaces Instance segmentations from backbones Wideresnet50 \cite {wideresnet} and Resnet50 \cite {He_2016resnet} on the novel flat connector class.}}{42}{figure.caption.50}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Example images of normal flat connectors.}}{52}{figure.caption.52}%
